{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ac88a8ea",
   "metadata": {},
   "source": [
    "# Step 1 - Frame Dividing Part"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cf6e90e",
   "metadata": {},
   "source": [
    "#### Install Opencv for Frame Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7aa0ec21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting opencv-python-headless\n",
      "  Using cached opencv_python_headless-4.11.0.86-cp37-abi3-win_amd64.whl.metadata (20 kB)\n",
      "Collecting numpy>=1.21.2 (from opencv-python-headless)\n",
      "  Downloading numpy-2.2.5-cp310-cp310-win_amd64.whl.metadata (60 kB)\n",
      "Using cached opencv_python_headless-4.11.0.86-cp37-abi3-win_amd64.whl (39.4 MB)\n",
      "Downloading numpy-2.2.5-cp310-cp310-win_amd64.whl (12.9 MB)\n",
      "   ---------------------------------------- 0.0/12.9 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/12.9 MB ? eta -:--:--\n",
      "   ------ --------------------------------- 2.1/12.9 MB 7.3 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 3.9/12.9 MB 8.1 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 6.6/12.9 MB 9.4 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 9.2/12.9 MB 10.2 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 11.5/12.9 MB 10.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  12.8/12.9 MB 10.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 12.9/12.9 MB 9.0 MB/s eta 0:00:00\n",
      "Installing collected packages: numpy, opencv-python-headless\n",
      "\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   -------------------- ------------------- 1/2 [opencv-python-headless]\n",
      "   -------------------- ------------------- 1/2 [opencv-python-headless]\n",
      "   -------------------- ------------------- 1/2 [opencv-python-headless]\n",
      "   -------------------- ------------------- 1/2 [opencv-python-headless]\n",
      "   ---------------------------------------- 2/2 [opencv-python-headless]\n",
      "\n",
      "Successfully installed numpy-2.2.5 opencv-python-headless-4.11.0.86\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install opencv-python-headless"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c55dbe94",
   "metadata": {},
   "source": [
    "#### Importing Libraries CV2 and OS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9cd218d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28af32fb",
   "metadata": {},
   "source": [
    "#### Function to Extract Frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "53894381",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_frames(video_path, output_folder, frame_rate=30):\n",
    "    \"\"\"Extract frames from a video at a given frame rate.\"\"\"\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS))  # Get video FPS\n",
    "\n",
    "    # Debug: Print FPS\n",
    "    print(f\"Video: {video_path}, FPS: {fps}\")\n",
    "\n",
    "    if fps == 0:\n",
    "        print(\"Error: Could not read FPS. Check the video file or codec.\")\n",
    "        return  # Exit function to prevent division by zero\n",
    "\n",
    "    frame_interval = max(1, int(fps / frame_rate))  # Avoid division by zero\n",
    "\n",
    "    count = 0\n",
    "    frame_id = 0\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break  # Stop when the video ends\n",
    "\n",
    "        if count % frame_interval == 0:\n",
    "            frame_filename = os.path.join(output_folder, f\"frame_{frame_id:04d}.jpg\")\n",
    "            cv2.imwrite(frame_filename, frame)\n",
    "            frame_id += 1  # Increment frame number\n",
    "\n",
    "        count += 1\n",
    "\n",
    "    cap.release()\n",
    "    print(f\" Extracted {frame_id} frames from {video_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c73c1be2",
   "metadata": {},
   "source": [
    "##### Extracting frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d98a9e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_frames(\"Video/Player02_FS_Set01_F_50Kg.MOV\", \"Output Video/frames/front\", frame_rate=30)\n",
    "extract_frames(\"Video/Player02_FS_Set01_S_50Kg.MOV\", \"Output Video/frames/side\", frame_rate=30)\n",
    "extract_frames(\"Video/Player02_FS_Set01_A_50Kg.mp4\", \"Output Video/frames/top\", frame_rate=30)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2c3b317",
   "metadata": {},
   "source": [
    "#### Check the orientation and Quality -Rotate if needed Automatically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1f557962",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "\n",
    "def check_orientation(folder_path):\n",
    "    \"\"\"\n",
    "    Automatically rotates portrait images in the given folder to landscape.\n",
    "    Overwrites the original image if rotated.\n",
    "    \"\"\"\n",
    "    for img_name in sorted(os.listdir(folder_path)):\n",
    "        img_path = os.path.join(folder_path, img_name)\n",
    "        img = cv2.imread(img_path)\n",
    "\n",
    "        if img is None:\n",
    "            print(f\"‚ö†Ô∏è Skipping unreadable image: {img_name}\")\n",
    "            continue\n",
    "\n",
    "        height, width, _ = img.shape\n",
    "\n",
    "        # Rotate only if it's in portrait orientation\n",
    "        if height > width:\n",
    "            img_rotated = cv2.rotate(img, cv2.ROTATE_90_CLOCKWISE)\n",
    "            cv2.imwrite(img_path, img_rotated)\n",
    "            print(f\"üîÑ Rotated {img_name} to landscape ({height}x{width}) ‚Üí ({img_rotated.shape[1]}x{img_rotated.shape[0]})\")\n",
    "        else:\n",
    "            print(f\"‚úÖ {img_name} already landscape ({width}x{height})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66b1f082",
   "metadata": {},
   "source": [
    "#### Remove Blurry Images from frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "105e241a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import shutil\n",
    "\n",
    "def detect_and_move_blurry_images(folder_path, default_threshold=120.0):\n",
    "    \"\"\"\n",
    "    Analyze blurriness of images using Laplacian variance.\n",
    "    Prompts for threshold input and moves blurry images to a separate folder.\n",
    "    \"\"\"\n",
    "    print(f\"\\nüîç Analyzing blurriness in: {folder_path}\")\n",
    "    blur_data = []\n",
    "\n",
    "    # Step 1: Collect and show blurriness variance\n",
    "    for img_name in sorted(os.listdir(folder_path)):\n",
    "        img_path = os.path.join(folder_path, img_name)\n",
    "        img = cv2.imread(img_path)\n",
    "        if img is None:\n",
    "            print(f\"‚ö†Ô∏è Skipping unreadable image: {img_name}\")\n",
    "            continue\n",
    "\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        variance = cv2.Laplacian(gray, cv2.CV_64F).var()\n",
    "        blur_data.append((img_name, variance))\n",
    "\n",
    "    # Display all variance scores\n",
    "    print(\"\\nüìä Blurriness Index (Higher is sharper):\")\n",
    "    for name, var in blur_data:\n",
    "        print(f\"{name}: Variance = {var:.2f}\")\n",
    "\n",
    "    # Step 2: Ask user for threshold\n",
    "    try:\n",
    "        threshold_input = input(f\"\\nEnter blurriness threshold [Default = {default_threshold}]: \")\n",
    "        threshold = float(threshold_input) if threshold_input.strip() else default_threshold\n",
    "    except ValueError:\n",
    "        print(\"‚ö†Ô∏è Invalid input. Using default threshold.\")\n",
    "        threshold = default_threshold\n",
    "\n",
    "    # Step 3: Move blurry images\n",
    "    blurry_folder = os.path.join(os.path.dirname(folder_path), f\"blurry_{os.path.basename(folder_path)}\")\n",
    "    os.makedirs(blurry_folder, exist_ok=True)\n",
    "\n",
    "    moved = 0\n",
    "    for name, var in blur_data:\n",
    "        if var < threshold:\n",
    "            src_path = os.path.join(folder_path, name)\n",
    "            dst_path = os.path.join(blurry_folder, name)\n",
    "            shutil.move(src_path, dst_path)\n",
    "            print(f\"üìÅ Moved blurry image: {name} (Variance = {var:.2f})\")\n",
    "            moved += 1\n",
    "\n",
    "    print(f\"\\n‚úÖ Done. {moved} blurry images moved to '{blurry_folder}'.\")\n",
    "\n",
    "# Example usage\n",
    "# detect_and_move_blurry_images(\"Output/extracted_frames/top\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23cf70c8",
   "metadata": {},
   "source": [
    "# Step 2 - Extracting Key points"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c7eea05",
   "metadata": {},
   "source": [
    "#### Install mediapipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "44c7b3d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting mediapipe\n",
      "  Using cached mediapipe-0.10.21-cp310-cp310-win_amd64.whl.metadata (10 kB)\n",
      "Requirement already satisfied: absl-py in c:\\users\\ds\\desktop\\ai model\\.venv\\lib\\site-packages (from mediapipe) (2.2.2)\n",
      "Requirement already satisfied: attrs>=19.1.0 in c:\\users\\ds\\desktop\\ai model\\.venv\\lib\\site-packages (from mediapipe) (25.3.0)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in c:\\users\\ds\\desktop\\ai model\\.venv\\lib\\site-packages (from mediapipe) (25.2.10)\n",
      "Collecting jax (from mediapipe)\n",
      "  Using cached jax-0.6.0-py3-none-any.whl.metadata (22 kB)\n",
      "Collecting jaxlib (from mediapipe)\n",
      "  Using cached jaxlib-0.6.0-cp310-cp310-win_amd64.whl.metadata (1.2 kB)\n",
      "Collecting matplotlib (from mediapipe)\n",
      "  Using cached matplotlib-3.10.1-cp310-cp310-win_amd64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: numpy<2 in c:\\users\\ds\\desktop\\ai model\\.venv\\lib\\site-packages (from mediapipe) (1.26.4)\n",
      "Collecting opencv-contrib-python (from mediapipe)\n",
      "  Using cached opencv_contrib_python-4.11.0.86-cp37-abi3-win_amd64.whl.metadata (20 kB)\n",
      "Requirement already satisfied: protobuf<5,>=4.25.3 in c:\\users\\ds\\desktop\\ai model\\.venv\\lib\\site-packages (from mediapipe) (4.25.7)\n",
      "Collecting sounddevice>=0.4.4 (from mediapipe)\n",
      "  Using cached sounddevice-0.5.1-py3-none-win_amd64.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: sentencepiece in c:\\users\\ds\\desktop\\ai model\\.venv\\lib\\site-packages (from mediapipe) (0.2.0)\n",
      "Collecting CFFI>=1.0 (from sounddevice>=0.4.4->mediapipe)\n",
      "  Using cached cffi-1.17.1-cp310-cp310-win_amd64.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: pycparser in c:\\users\\ds\\desktop\\ai model\\.venv\\lib\\site-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe) (2.22)\n",
      "Collecting ml_dtypes>=0.5.0 (from jax->mediapipe)\n",
      "  Using cached ml_dtypes-0.5.1-cp310-cp310-win_amd64.whl.metadata (22 kB)\n",
      "Requirement already satisfied: opt_einsum in c:\\users\\ds\\desktop\\ai model\\.venv\\lib\\site-packages (from jax->mediapipe) (3.4.0)\n",
      "Requirement already satisfied: scipy>=1.11.1 in c:\\users\\ds\\desktop\\ai model\\.venv\\lib\\site-packages (from jax->mediapipe) (1.15.2)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib->mediapipe)\n",
      "  Using cached contourpy-1.3.2-cp310-cp310-win_amd64.whl.metadata (5.5 kB)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\ds\\desktop\\ai model\\.venv\\lib\\site-packages (from matplotlib->mediapipe) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\ds\\desktop\\ai model\\.venv\\lib\\site-packages (from matplotlib->mediapipe) (4.57.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\ds\\desktop\\ai model\\.venv\\lib\\site-packages (from matplotlib->mediapipe) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\ds\\desktop\\ai model\\.venv\\lib\\site-packages (from matplotlib->mediapipe) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\ds\\desktop\\ai model\\.venv\\lib\\site-packages (from matplotlib->mediapipe) (11.2.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\ds\\desktop\\ai model\\.venv\\lib\\site-packages (from matplotlib->mediapipe) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\ds\\desktop\\ai model\\.venv\\lib\\site-packages (from matplotlib->mediapipe) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\ds\\desktop\\ai model\\.venv\\lib\\site-packages (from python-dateutil>=2.7->matplotlib->mediapipe) (1.17.0)\n",
      "Using cached mediapipe-0.10.21-cp310-cp310-win_amd64.whl (51.0 MB)\n",
      "Using cached sounddevice-0.5.1-py3-none-win_amd64.whl (363 kB)\n",
      "Using cached cffi-1.17.1-cp310-cp310-win_amd64.whl (181 kB)\n",
      "Using cached jax-0.6.0-py3-none-any.whl (2.3 MB)\n",
      "Using cached jaxlib-0.6.0-cp310-cp310-win_amd64.whl (56.4 MB)\n",
      "Using cached ml_dtypes-0.5.1-cp310-cp310-win_amd64.whl (209 kB)\n",
      "Using cached matplotlib-3.10.1-cp310-cp310-win_amd64.whl (8.1 MB)\n",
      "Using cached contourpy-1.3.2-cp310-cp310-win_amd64.whl (221 kB)\n",
      "Using cached opencv_contrib_python-4.11.0.86-cp37-abi3-win_amd64.whl (46.2 MB)\n",
      "Installing collected packages: opencv-contrib-python, ml_dtypes, contourpy, CFFI, sounddevice, matplotlib, jaxlib, jax, mediapipe\n",
      "\n",
      "   ---------------------------------------- 0/9 [opencv-contrib-python]\n",
      "   ---------------------------------------- 0/9 [opencv-contrib-python]\n",
      "   ---------------------------------------- 0/9 [opencv-contrib-python]\n",
      "   ---------------------------------------- 0/9 [opencv-contrib-python]\n",
      "   ------------- -------------------------- 3/9 [CFFI]\n",
      "   ---------------------- ----------------- 5/9 [matplotlib]\n",
      "   ---------------------- ----------------- 5/9 [matplotlib]\n",
      "   ---------------------- ----------------- 5/9 [matplotlib]\n",
      "   ---------------------- ----------------- 5/9 [matplotlib]\n",
      "   ---------------------- ----------------- 5/9 [matplotlib]\n",
      "   ---------------------- ----------------- 5/9 [matplotlib]\n",
      "   ---------------------- ----------------- 5/9 [matplotlib]\n",
      "   ---------------------- ----------------- 5/9 [matplotlib]\n",
      "   ---------------------- ----------------- 5/9 [matplotlib]\n",
      "   ---------------------- ----------------- 5/9 [matplotlib]\n",
      "   ---------------------- ----------------- 5/9 [matplotlib]\n",
      "   ---------------------- ----------------- 5/9 [matplotlib]\n",
      "   -------------------------- ------------- 6/9 [jaxlib]\n",
      "   -------------------------- ------------- 6/9 [jaxlib]\n",
      "   -------------------------- ------------- 6/9 [jaxlib]\n",
      "   -------------------------- ------------- 6/9 [jaxlib]\n",
      "   -------------------------- ------------- 6/9 [jaxlib]\n",
      "   -------------------------- ------------- 6/9 [jaxlib]\n",
      "   -------------------------- ------------- 6/9 [jaxlib]\n",
      "   ------------------------------- -------- 7/9 [jax]\n",
      "   ------------------------------- -------- 7/9 [jax]\n",
      "   ------------------------------- -------- 7/9 [jax]\n",
      "   ------------------------------- -------- 7/9 [jax]\n",
      "   ------------------------------- -------- 7/9 [jax]\n",
      "   ------------------------------- -------- 7/9 [jax]\n",
      "   ------------------------------- -------- 7/9 [jax]\n",
      "   ------------------------------- -------- 7/9 [jax]\n",
      "   ------------------------------- -------- 7/9 [jax]\n",
      "   ------------------------------- -------- 7/9 [jax]\n",
      "   ------------------------------- -------- 7/9 [jax]\n",
      "   ------------------------------- -------- 7/9 [jax]\n",
      "   ------------------------------- -------- 7/9 [jax]\n",
      "   ------------------------------- -------- 7/9 [jax]\n",
      "   ----------------------------------- ---- 8/9 [mediapipe]\n",
      "   ----------------------------------- ---- 8/9 [mediapipe]\n",
      "   ----------------------------------- ---- 8/9 [mediapipe]\n",
      "   ----------------------------------- ---- 8/9 [mediapipe]\n",
      "   ----------------------------------- ---- 8/9 [mediapipe]\n",
      "   ----------------------------------- ---- 8/9 [mediapipe]\n",
      "   ----------------------------------- ---- 8/9 [mediapipe]\n",
      "   ----------------------------------- ---- 8/9 [mediapipe]\n",
      "   ----------------------------------- ---- 8/9 [mediapipe]\n",
      "   ----------------------------------- ---- 8/9 [mediapipe]\n",
      "   ----------------------------------- ---- 8/9 [mediapipe]\n",
      "   ----------------------------------- ---- 8/9 [mediapipe]\n",
      "   ----------------------------------- ---- 8/9 [mediapipe]\n",
      "   ---------------------------------------- 9/9 [mediapipe]\n",
      "\n",
      "Successfully installed CFFI-1.17.1 contourpy-1.3.2 jax-0.6.0 jaxlib-0.6.0 matplotlib-3.10.1 mediapipe-0.10.21 ml_dtypes-0.5.1 opencv-contrib-python-4.11.0.86 sounddevice-0.5.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install mediapipe\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a9cf4f",
   "metadata": {},
   "source": [
    "#### Detect Keypoints - Annotate the Frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "75ec6867",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import os\n",
    "\n",
    "# Initialize MediaPipe Pose model\n",
    "mp_pose = mp.solutions.pose\n",
    "pose = mp_pose.Pose()\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "def detect_keypoints(input_folder, output_folder):\n",
    "    \"\"\"Detects keypoints in images and saves annotated frames.\"\"\"\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    for img_name in sorted(os.listdir(input_folder)):\n",
    "        img_path = os.path.join(input_folder, img_name)\n",
    "        image = cv2.imread(img_path)\n",
    "\n",
    "        if image is None:\n",
    "            continue  # Skip if image is corrupted\n",
    "\n",
    "        # Convert BGR to RGB (MediaPipe expects RGB)\n",
    "        rgb_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        results = pose.process(rgb_image)\n",
    "\n",
    "        if results.pose_landmarks:\n",
    "            # Draw keypoints on the image\n",
    "            mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS)\n",
    "\n",
    "        # Save the output image\n",
    "        output_path = os.path.join(output_folder, img_name)\n",
    "        cv2.imwrite(output_path, image)\n",
    "\n",
    "    print(f\"‚úÖ Keypoint detection completed. Output saved in {output_folder}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a86d888e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "detect_keypoints(\"Output Video/frames/front\", \"Output Video/keypoints/front\")\n",
    "detect_keypoints(\"Output Video/frames/side\", \"Output Video/keypoints/side\")\n",
    "detect_keypoints(\"Output Video/frames/top\", \"Output Video/keypoints/top\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "218aeedb",
   "metadata": {},
   "source": [
    "#### Extract 2D Key Point Data into Json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "71aa7083",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import os\n",
    "import json\n",
    "\n",
    "# Initialize MediaPipe Pose model\n",
    "mp_pose = mp.solutions.pose\n",
    "pose = mp_pose.Pose()\n",
    "\n",
    "def extract_2d_keypoints(input_folder, output_json):\n",
    "    \"\"\"Extracts 2D keypoints from images and saves them to a JSON file.\"\"\"\n",
    "    keypoints_data = {}\n",
    "\n",
    "    for img_name in sorted(os.listdir(input_folder)):  # Process frames in order\n",
    "        img_path = os.path.join(input_folder, img_name)\n",
    "        image = cv2.imread(img_path)\n",
    "\n",
    "        if image is None:\n",
    "            continue  # Skip if image is corrupted\n",
    "\n",
    "        # Convert BGR to RGB (MediaPipe expects RGB)\n",
    "        rgb_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        results = pose.process(rgb_image)\n",
    "\n",
    "        frame_keypoints = []\n",
    "        if results.pose_landmarks:\n",
    "            for landmark in results.pose_landmarks.landmark:\n",
    "                frame_keypoints.append((landmark.x, landmark.y))  # Store (x, y) only\n",
    "\n",
    "        keypoints_data[img_name] = frame_keypoints  # Store keypoints for this frame\n",
    "\n",
    "    # Save results to JSON\n",
    "    with open(output_json, 'w') as f:\n",
    "        json.dump(keypoints_data, f, indent=4)\n",
    "\n",
    "    print(f\"‚úÖ 2D keypoints extracted and saved to {output_json}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "208c4a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage (Extract for front, side, and top views)\n",
    "extract_2d_keypoints(\"Output Video/frames/front\", \"Output Video/keypoints/front.json\")\n",
    "extract_2d_keypoints(\"Output Video/frames/side\", \"Output Video/keypoints/side.json\")\n",
    "extract_2d_keypoints(\"Output Video/frames/top\", \"Output Video/keypoints/top.json\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1345a5da",
   "metadata": {},
   "source": [
    "#### Normalize the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a926a61",
   "metadata": {},
   "source": [
    "- No need Because MediaPipe Already Normalize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71ea923e",
   "metadata": {},
   "source": [
    "#### Pose Completness Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d544c8fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "# Initialize MediaPipe Pose\n",
    "mp_pose = mp.solutions.pose\n",
    "pose = mp_pose.Pose()\n",
    "\n",
    "def check_pose_completeness_and_move(input_folder, bad_folder, min_visible=25, visibility_threshold=0.5):\n",
    "    \"\"\"\n",
    "    Checks pose completeness and moves frames with low keypoint visibility to a separate folder.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(bad_folder):\n",
    "        os.makedirs(bad_folder)\n",
    "\n",
    "    print(f\"üîç Checking pose completeness in: {input_folder}\")\n",
    "    incomplete_frames = []\n",
    "\n",
    "    for img_name in sorted(os.listdir(input_folder)):\n",
    "        img_path = os.path.join(input_folder, img_name)\n",
    "        image = cv2.imread(img_path)\n",
    "\n",
    "        if image is None:\n",
    "            continue\n",
    "\n",
    "        rgb_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        results = pose.process(rgb_image)\n",
    "\n",
    "        visible_count = 0\n",
    "        if results.pose_landmarks:\n",
    "            for landmark in results.pose_landmarks.landmark:\n",
    "                if landmark.visibility >= visibility_threshold:\n",
    "                    visible_count += 1\n",
    "\n",
    "        if visible_count < min_visible:\n",
    "            incomplete_frames.append((img_name, visible_count))\n",
    "            print(f\"‚ö†Ô∏è Incomplete pose in {img_name}: {visible_count}/33 visible\")\n",
    "\n",
    "            # Move the bad frame\n",
    "            shutil.move(img_path, os.path.join(bad_folder, img_name))\n",
    "\n",
    "    print(f\"\\nüìâ Moved {len(incomplete_frames)} incomplete frames to '{bad_folder}'\")\n",
    "    return incomplete_frames\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "702d37e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move bad top-view frames\n",
    "check_pose_completeness_and_move(\n",
    "    input_folder=\"Output Video/frames/top\",\n",
    "    bad_folder=\"Output Video/frames/top_bad\"\n",
    ")\n",
    "\n",
    "# You can run it for front or side too\n",
    "# check_pose_completeness_and_move(\"Output Video/frames/front\", \"Output Video/frames/front_bad\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4213c8c",
   "metadata": {},
   "source": [
    "#### Visualize Annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c02c4745",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the image\n",
    "image = plt.imread(\"Output Video/frames/front/frame_0000.jpg\")\n",
    "height, width, _ = image.shape\n",
    "\n",
    "# Convert normalized keypoints to pixel values\n",
    "x_pixels = [x * width for x, y in keypoints]\n",
    "y_pixels = [y * height for x, y in keypoints]\n",
    "\n",
    "# Display image and overlay points\n",
    "plt.imshow(image)\n",
    "plt.scatter(x_pixels, y_pixels, c=\"red\", marker=\"o\")  # Red dots for keypoints\n",
    "plt.title(\"MediaPipe Pose Annotations\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6da9c362",
   "metadata": {},
   "source": [
    "#### Manually Update Annoatations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c07513b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "image_path = \"Output Video/frames/front/frame_0000.jpg\"\n",
    "image = cv2.imread(image_path)\n",
    "height, width, _ = image.shape\n",
    "\n",
    "# Replace with your actual keypoints (normalized)\n",
    "keypoints = [\n",
    "        [\n",
    "            0.5505455732345581,\n",
    "            0.5588361024856567\n",
    "        ],\n",
    "        [\n",
    "            0.5572452545166016,\n",
    "            0.552212119102478\n",
    "        ],\n",
    "        [\n",
    "            0.5614649653434753,\n",
    "            0.5519828200340271\n",
    "        ],\n",
    "        [\n",
    "            0.5650237202644348,\n",
    "            0.5518215894699097\n",
    "        ],\n",
    "        [\n",
    "            0.5457234382629395,\n",
    "            0.5524178743362427\n",
    "        ],\n",
    "        [\n",
    "            0.542575478553772,\n",
    "            0.5522381067276001\n",
    "        ],\n",
    "        [\n",
    "            0.5397322773933411,\n",
    "            0.5520192980766296\n",
    "        ],\n",
    "        [\n",
    "            0.5709152817726135,\n",
    "            0.551386833190918\n",
    "        ],\n",
    "        [\n",
    "            0.5365363359451294,\n",
    "            0.5507765412330627\n",
    "        ],\n",
    "        [\n",
    "            0.5573853850364685,\n",
    "            0.5633068680763245\n",
    "        ],\n",
    "        [\n",
    "            0.5449458360671997,\n",
    "            0.5633752346038818\n",
    "        ],\n",
    "        [\n",
    "            0.6019920110702515,\n",
    "            0.5733140110969543\n",
    "        ],\n",
    "        [\n",
    "            0.5090041756629944,\n",
    "            0.5722963213920593\n",
    "        ],\n",
    "        [\n",
    "            0.6641108989715576,\n",
    "            0.5980207920074463\n",
    "        ],\n",
    "        [\n",
    "            0.4531230330467224,\n",
    "            0.5994670391082764\n",
    "        ],\n",
    "        [\n",
    "            0.6960875988006592,\n",
    "            0.6336801648139954\n",
    "        ],\n",
    "        [\n",
    "            0.4205382168292999,\n",
    "            0.6375626921653748\n",
    "        ],\n",
    "        [\n",
    "            0.7118327617645264,\n",
    "            0.6432164907455444\n",
    "        ],\n",
    "        [\n",
    "            0.410492867231369,\n",
    "            0.6457881331443787\n",
    "        ],\n",
    "        [\n",
    "            0.7016799449920654,\n",
    "            0.6457731127738953\n",
    "        ],\n",
    "        [\n",
    "            0.42393040657043457,\n",
    "            0.6460126042366028\n",
    "        ],\n",
    "        [\n",
    "            0.6945846676826477,\n",
    "            0.6432654857635498\n",
    "        ],\n",
    "        [\n",
    "            0.42746487259864807,\n",
    "            0.6433942914009094\n",
    "        ],\n",
    "        [\n",
    "            0.5882201790809631,\n",
    "            0.6286242008209229\n",
    "        ],\n",
    "        [\n",
    "            0.5343642830848694,\n",
    "            0.6304098963737488\n",
    "        ],\n",
    "        [\n",
    "            0.6483628749847412,\n",
    "            0.6160215735435486\n",
    "        ],\n",
    "        [\n",
    "            0.46625185012817383,\n",
    "            0.6172221899032593\n",
    "        ],\n",
    "        [\n",
    "            0.6089972853660583,\n",
    "            0.656097948551178\n",
    "        ],\n",
    "        [\n",
    "            0.5100529193878174,\n",
    "            0.6553679704666138\n",
    "        ],\n",
    "        [\n",
    "            0.6025288105010986,\n",
    "            0.6603747606277466\n",
    "        ],\n",
    "        [\n",
    "            0.518900454044342,\n",
    "            0.658387303352356\n",
    "        ],\n",
    "        [\n",
    "            0.6210933923721313,\n",
    "            0.6730417609214783\n",
    "        ],\n",
    "        [\n",
    "            0.47687360644340515,\n",
    "            0.6730539202690125\n",
    "        ]\n",
    "    ]\n",
    "\n",
    "# Convert to pixel coordinates\n",
    "keypoints_px = [(int(x * width), int(y * height)) for x, y in keypoints]\n",
    "\n",
    "# For dragging\n",
    "dragging = False\n",
    "drag_index = -1\n",
    "undo_stack = []\n",
    "\n",
    "def draw_points(img, points):\n",
    "    for i, (x, y) in enumerate(points):\n",
    "        cv2.circle(img, (x, y), 5, (0, 255, 0), -1)\n",
    "        cv2.putText(img, str(i), (x + 5, y - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.4, (0, 255, 255), 1)\n",
    "\n",
    "def get_nearest_point(x, y, points, radius=10):\n",
    "    for i, (px, py) in enumerate(points):\n",
    "        if abs(px - x) <= radius and abs(py - y) <= radius:\n",
    "            return i\n",
    "    return -1\n",
    "\n",
    "def mouse_callback(event, x, y, flags, param):\n",
    "    global dragging, drag_index, keypoints_px, undo_stack\n",
    "\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        idx = get_nearest_point(x, y, keypoints_px)\n",
    "        if idx != -1:\n",
    "            dragging = True\n",
    "            drag_index = idx\n",
    "            undo_stack.append(keypoints_px.copy())  # Save previous state\n",
    "    elif event == cv2.EVENT_MOUSEMOVE:\n",
    "        if dragging and drag_index != -1:\n",
    "            keypoints_px[drag_index] = (x, y)\n",
    "    elif event == cv2.EVENT_LBUTTONUP:\n",
    "        dragging = False\n",
    "        drag_index = -1\n",
    "\n",
    "cv2.namedWindow(\"Adjust Keypoints\", cv2.WINDOW_NORMAL)\n",
    "cv2.resizeWindow(\"Adjust Keypoints\", 640, 480)\n",
    "cv2.setMouseCallback(\"Adjust Keypoints\", mouse_callback)\n",
    "\n",
    "while True:\n",
    "    temp_image = image.copy()\n",
    "    draw_points(temp_image, keypoints_px)\n",
    "    cv2.imshow(\"Adjust Keypoints\", temp_image)\n",
    "    key = cv2.waitKey(1)\n",
    "\n",
    "    if key == ord('q'):  # Quit and save\n",
    "        break\n",
    "    elif key == ord('u'):  # Undo\n",
    "        if undo_stack:\n",
    "            keypoints_px = undo_stack.pop()\n",
    "            print(\"Undo last move.\")\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# Convert to normalized keypoints\n",
    "updated_keypoints = [[x / width, y / height] for x, y in keypoints_px]\n",
    "print(\"Updated normalized keypoints:\")\n",
    "for point in updated_keypoints:\n",
    "    print(point)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f69bbb6",
   "metadata": {},
   "source": [
    "#### Saving Image MetaData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b309257",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import json\n",
    "\n",
    "def store_frame_metadata(image_folder, output_metadata_json):\n",
    "    \"\"\"\n",
    "    Stores metadata (filename, resolution, etc.) for annotated frames in a JSON file.\n",
    "    \"\"\"\n",
    "    metadata = {}\n",
    "\n",
    "    for img_name in sorted(os.listdir(image_folder)):\n",
    "        img_path = os.path.join(image_folder, img_name)\n",
    "        image = cv2.imread(img_path)\n",
    "\n",
    "        if image is None:\n",
    "            continue\n",
    "\n",
    "        height, width, channels = image.shape\n",
    "        metadata[img_name] = {\n",
    "            \"resolution\": f\"{width}x{height}\",\n",
    "            \"width\": width,\n",
    "            \"height\": height,\n",
    "            \"channels\": channels,\n",
    "            \"path\": img_path\n",
    "            # You can add more info here like timestamp if available\n",
    "        }\n",
    "\n",
    "    # Save metadata to JSON\n",
    "    with open(output_metadata_json, 'w') as f:\n",
    "        json.dump(metadata, f, indent=4)\n",
    "\n",
    "    print(f\"üìù Metadata saved to {output_metadata_json}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c73789cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "store_frame_metadata(\"Output Video/keypoints/front\", \"Output Video/keypoints/front_metadata.json\")\n",
    "store_frame_metadata(\"Output Video/keypoints/side\", \"Output Video/keypoints/side_metadata.json\")\n",
    "store_frame_metadata(\"Output Video/keypoints/top\", \"Output Video/keypoints/top_metadata.json\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f749a590",
   "metadata": {},
   "source": [
    "pipe;ine\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "190de439",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import json\n",
    "import csv\n",
    "from datetime import datetime\n",
    "\n",
    "# ======================= #\n",
    "# ==== CONFIGURATION ==== #\n",
    "# ======================= #\n",
    "\n",
    "# Hardcoded output paths for consistency\n",
    "FRAMES_ROOT = \"Output/frames\"\n",
    "KEYPOINTS_ROOT = \"Output/keypoints\"\n",
    "ANNOTATIONS_ROOT = \"Output/annotations\"\n",
    "LOG_FILE = \"Output/processing_log.txt\"\n",
    "CENTRAL_INDEX_FILE = \"Output/central_index.csv\"\n",
    "\n",
    "# Create all required output folders at startup\n",
    "for path in [FRAMES_ROOT, KEYPOINTS_ROOT, ANNOTATIONS_ROOT, os.path.dirname(LOG_FILE)]:\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "\n",
    "# =============================== #\n",
    "# ==== UTILITY HELPER FUNCS ==== #\n",
    "# =============================== #\n",
    "\n",
    "def get_all_video_paths(root_folder, extensions=(\".mp4\", \".mov\")):\n",
    "    video_paths = []\n",
    "    for dirpath, _, filenames in os.walk(root_folder):\n",
    "        for file in filenames:\n",
    "            if file.lower().endswith(extensions):\n",
    "                video_paths.append(os.path.join(dirpath, file))\n",
    "    return video_paths\n",
    "\n",
    "def get_relative_path(video_path, root_folder):\n",
    "    return os.path.relpath(video_path, root_folder)\n",
    "\n",
    "def build_output_paths(video_path, root_input_folder):\n",
    "    relative_path = get_relative_path(video_path, root_input_folder)\n",
    "    base = os.path.splitext(relative_path)[0]\n",
    "    return {\n",
    "        \"frames\": os.path.join(FRAMES_ROOT, base),\n",
    "        \"keypoints\": os.path.join(KEYPOINTS_ROOT, base),\n",
    "        \"annotations\": os.path.join(ANNOTATIONS_ROOT, base),\n",
    "        \"metadata\": os.path.join(KEYPOINTS_ROOT, base, \"metadata.json\")\n",
    "    }\n",
    "\n",
    "def has_been_processed(paths):\n",
    "    return os.path.exists(paths[\"metadata\"])\n",
    "\n",
    "def log_message(message):\n",
    "    timestamp = f\"{datetime.now()} - {message}\"\n",
    "    os.makedirs(os.path.dirname(LOG_FILE), exist_ok=True)\n",
    "    with open(LOG_FILE, \"a\", encoding=\"utf-8\") as log_file:\n",
    "        log_file.write(timestamp + \"\\n\")\n",
    "    print(timestamp)\n",
    "\n",
    "def save_metadata(metadata_path, data):\n",
    "    os.makedirs(os.path.dirname(metadata_path), exist_ok=True)\n",
    "    with open(metadata_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(data, f, indent=4)\n",
    "\n",
    "def update_central_index(index_file, row):\n",
    "    os.makedirs(os.path.dirname(index_file), exist_ok=True)\n",
    "    file_exists = os.path.exists(index_file)\n",
    "    with open(index_file, \"a\", newline=\"\", encoding=\"utf-8\") as csvfile:\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=row.keys())\n",
    "        if not file_exists:\n",
    "            writer.writeheader()\n",
    "        writer.writerow(row)\n",
    "\n",
    "# ===================================== #\n",
    "# ==== MAIN VIDEO PROCESSOR FUNC  ==== #\n",
    "# ===================================== #\n",
    "\n",
    "def process_all_videos(root_input_folder):\n",
    "    videos = get_all_video_paths(root_input_folder)\n",
    "    log_message(f\"üé¨ Found {len(videos)} videos under '{root_input_folder}'\")\n",
    "\n",
    "    for video_path in videos:\n",
    "        paths = build_output_paths(video_path, root_input_folder)\n",
    "        if has_been_processed(paths):\n",
    "            log_message(f\"‚è≠Ô∏è Skipping already processed: {video_path}\")\n",
    "            continue\n",
    "\n",
    "        # Create required output folders\n",
    "        for key in [\"frames\", \"keypoints\", \"annotations\"]:\n",
    "            os.makedirs(paths[key], exist_ok=True)\n",
    "\n",
    "        try:\n",
    "            # ====== MAIN PIPELINE STEPS ======\n",
    "            extract_frames(video_path, paths[\"frames\"])  # STEP 1\n",
    "            detect_keypoints(paths[\"frames\"], paths[\"keypoints\"])  # STEP 2\n",
    "            extract_2d_keypoints(paths[\"keypoints\"], os.path.join(paths[\"keypoints\"], \"keypoints.json\"))  # STEP 3\n",
    "\n",
    "\n",
    "            # ====== Save metadata ======\n",
    "            metadata = {\n",
    "                \"video\": video_path,\n",
    "                \"processed_at\": str(datetime.now()),\n",
    "                \"frames_folder\": paths[\"frames\"],\n",
    "                \"keypoints_json\": os.path.join(paths[\"keypoints\"], \"keypoints.json\")\n",
    "            }\n",
    "            save_metadata(paths[\"metadata\"], metadata)\n",
    "\n",
    "            # ====== Update tracking CSV ======\n",
    "            update_central_index(CENTRAL_INDEX_FILE, {\n",
    "                \"video_path\": video_path,\n",
    "                \"frames_folder\": paths[\"frames\"],\n",
    "                \"keypoints_folder\": paths[\"keypoints\"],\n",
    "                \"annotation_folder\": paths[\"annotations\"],\n",
    "                \"processed_at\": metadata[\"processed_at\"]\n",
    "            })\n",
    "\n",
    "            log_message(f\"‚úÖ Processed: {video_path}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            log_message(f\"‚ùå Error processing {video_path}: {str(e)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fb155eb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-08 15:43:36.887474 - üé¨ Found 9 videos under 'Source'\n",
      "Video: Source\\Front\\CP\\Player02_CP_Set01_A_60Kg.mp4, FPS: 30\n",
      " Extracted 204 frames from Source\\Front\\CP\\Player02_CP_Set01_A_60Kg.mp4\n",
      "2025-05-08 15:43:45.211922 - ‚ùå Error processing Source\\Front\\CP\\Player02_CP_Set01_A_60Kg.mp4: name 'check_orientation' is not defined\n",
      "Video: Source\\Front\\CP\\Player02_CP_Set02_A_80Kg.mp4, FPS: 30\n",
      " Extracted 189 frames from Source\\Front\\CP\\Player02_CP_Set02_A_80Kg.mp4\n",
      "2025-05-08 15:43:52.517081 - ‚ùå Error processing Source\\Front\\CP\\Player02_CP_Set02_A_80Kg.mp4: name 'check_orientation' is not defined\n",
      "Video: Source\\Front\\CP\\Player02_CP_Set03_A_90Kg.mp4, FPS: 30\n",
      " Extracted 238 frames from Source\\Front\\CP\\Player02_CP_Set03_A_90Kg.mp4\n",
      "2025-05-08 15:44:01.638609 - ‚ùå Error processing Source\\Front\\CP\\Player02_CP_Set03_A_90Kg.mp4: name 'check_orientation' is not defined\n",
      "Video: Source\\Side\\CP\\Player02_CP_Set01_S_60Kg.MOV, FPS: 59\n",
      " Extracted 340 frames from Source\\Side\\CP\\Player02_CP_Set01_S_60Kg.MOV\n",
      "2025-05-08 15:44:14.312909 - ‚ùå Error processing Source\\Side\\CP\\Player02_CP_Set01_S_60Kg.MOV: name 'check_orientation' is not defined\n",
      "Video: Source\\Side\\CP\\Player02_CP_Set02_S_80Kg.MOV, FPS: 59\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[30], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mprocess_all_videos\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mSource\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[28], line 91\u001b[0m, in \u001b[0;36mprocess_all_videos\u001b[1;34m(root_input_folder)\u001b[0m\n\u001b[0;32m     87\u001b[0m     os\u001b[38;5;241m.\u001b[39mmakedirs(paths[key], exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     89\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     90\u001b[0m     \u001b[38;5;66;03m# ====== MAIN PIPELINE STEPS ======\u001b[39;00m\n\u001b[1;32m---> 91\u001b[0m     \u001b[43mextract_frames\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvideo_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpaths\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mframes\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# STEP 1\u001b[39;00m\n\u001b[0;32m     92\u001b[0m     check_orientation(paths[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mframes\u001b[39m\u001b[38;5;124m\"\u001b[39m])           \u001b[38;5;66;03m# STEP 2\u001b[39;00m\n\u001b[0;32m     95\u001b[0m     \u001b[38;5;66;03m# ====== Save metadata ======\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[25], line 22\u001b[0m, in \u001b[0;36mextract_frames\u001b[1;34m(video_path, output_folder, frame_rate)\u001b[0m\n\u001b[0;32m     19\u001b[0m frame_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m cap\u001b[38;5;241m.\u001b[39misOpened():\n\u001b[1;32m---> 22\u001b[0m     ret, frame \u001b[38;5;241m=\u001b[39m \u001b[43mcap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     23\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ret:\n\u001b[0;32m     24\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m  \u001b[38;5;66;03m# Stop when the video ends\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "process_all_videos(\"Source\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
